from opensearchpy import OpenSearch
from typing import List, Dict, Any, Optional
import hashlib
import json
from datetime import datetime
import urllib3
import os  # ì´ ì¤„ ì¶”ê°€
from dotenv import load_dotenv

load_dotenv()

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# local
# def create_opensearch_client() -> OpenSearch:
#     """OpenSearch í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
#     return OpenSearch(
#         hosts=[{
#             'host': os.getenv('OPENSEARCH_HOST', 'localhost'), 
#             'port': int(os.getenv('OPENSEARCH_PORT', '9200'))
#         }],
#         http_auth=(
#             os.getenv('OPENSEARCH_USERNAME', 'admin'),
#             os.getenv('OPENSEARCH_PASSWORD')  # ê¸°ë³¸ê°’ ì œê±°
#         ),
#         use_ssl=os.getenv('OPENSEARCH_USE_SSL', 'true').lower() == 'true',
#         verify_certs=False
#     )

# aws
def create_opensearch_client() -> OpenSearch:
    """OpenSearch í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    username = os.getenv('OPENSEARCH_USERNAME')
    password = os.getenv('OPENSEARCH_PASSWORD')
    http_auth = (username, password) if username and password else None

    return OpenSearch(
        hosts=[{
            'host': os.getenv('OPENSEARCH_HOST', 'localhost'),
            'port': int(os.getenv('OPENSEARCH_PORT', '9200'))
        }],
        http_auth=http_auth,
        use_ssl=os.getenv('OPENSEARCH_USE_SSL', 'true').lower() == 'true',
        verify_certs=False  # í…ŒìŠ¤íŠ¸ ì‹œ False, ìš´ì˜ì—ì„œëŠ” True
    )



def reset_index_with_embeddings(client: OpenSearch, index_name: str = "document-chunks"):
    """
    ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ì„ë² ë”© ì§€ì›ì´ í¬í•¨ëœ ìƒˆ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
    """
    try:
        # ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ì‚­ì œ
        if client.indices.exists(index=index_name):
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ {index_name} ì‚­ì œ ì¤‘...")
            client.indices.delete(index=index_name)
            print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ {index_name} ì‚­ì œ ì™„ë£Œ")
        
        # ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ì„¤ì • (knn_vector íƒ€ì… ì‚¬ìš©)
        index_settings = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 1,
                "index.knn": True  # KNN í”ŒëŸ¬ê·¸ì¸ í™œì„±í™”
            },
            "mappings": {
                "properties": {
                    "chunk_id": {"type": "integer"},
                    "content": {"type": "text"},
                    "document_name": {"type": "keyword"},
                    "timestamp": {"type": "date"},
                    "metadata": {"type": "object"},
                    "embedding": {
                        "type": "knn_vector",
                        "dimension": 1536,
                        "method": {
                            "name": "hnsw",
                            "space_type": "cosinesimil",
                            "engine": "lucene"
                        }
                    }
                }
            }
        }
        
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
        print(f"ğŸ”„ ìƒˆ ì¸ë±ìŠ¤ {index_name} ìƒì„± ì¤‘...")
        client.indices.create(index=index_name, body=index_settings)
        print(f"âœ… ìƒˆ ì¸ë±ìŠ¤ {index_name} ìƒì„± ì™„ë£Œ!")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì¸ë±ìŠ¤ ì¬ì„¤ì • ì‹¤íŒ¨: {e}")
        return False

def save_chunks_to_opensearch(
    chunks: List[str], 
    client: OpenSearch,
    document_name: str,
    metadata: Optional[Dict[str, Any]] = None,
    embeddings: Optional[List[List[float]]] = None,
    index_name: str = "document-chunks"
) -> List[str]:
    """
    Upstageì—ì„œ ìƒì„±ëœ ì²­í¬ë“¤ì„ OpenSearchì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        chunks: ì €ì¥í•  ì²­í¬ ë¦¬ìŠ¤íŠ¸
        client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        document_name: ë¬¸ì„œ ì´ë¦„
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        embeddings: ì²­í¬ì— ëŒ€ì‘í•˜ëŠ” ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        
    Returns:
        ì €ì¥ëœ ë¬¸ì„œ ID ëª©ë¡
    """
    # ì¸ë±ìŠ¤ê°€ ì—†ë‹¤ë©´ ìƒì„±
    if not client.indices.exists(index=index_name):
        index_settings = {
            "settings": {
                "number_of_shards": 1,
                "number_of_replicas": 1,
                "index.knn": True  # KNN í”ŒëŸ¬ê·¸ì¸ í™œì„±í™”
            },
            "mappings": {
                "properties": {
                    "chunk_id": {"type": "integer"},
                    "content": {"type": "text"},
                    "document_name": {"type": "keyword"},
                    "timestamp": {"type": "date"},
                    "metadata": {"type": "object"},
                    "embedding": {
                        "type": "knn_vector",
                        "dimension": 1536,
                        "method": {
                            "name": "hnsw",
                            "space_type": "cosinesimil",
                            "engine": "lucene"
                        }
                    }
                }
            }
        }
        client.indices.create(index=index_name, body=index_settings)
        print(f"âœ… ì¸ë±ìŠ¤ ìƒì„±ë¨: {index_name}")
    
    saved_ids = []
    timestamp = datetime.now().isoformat()
    
    # ê° ì²­í¬ë¥¼ ì €ì¥
    for i, chunk in enumerate(chunks):
        # ë¬¸ì„œ ID ìƒì„± (ë¬¸ì„œëª… + ì²­í¬ ì¸ë±ìŠ¤ì˜ í•´ì‹œ)
        doc_id = hashlib.md5(f"{document_name}_chunk_{i}".encode()).hexdigest()
        
        doc = {
            "chunk_id": i,
            "content": chunk.strip(),
            "document_name": document_name,
            "timestamp": timestamp,
            "metadata": metadata or {}
        }
        
        # ì„ë² ë”©ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if embeddings and i < len(embeddings):
            doc["embedding"] = embeddings[i]
        
        try:
            response = client.index(
                index=index_name, 
                id=doc_id,
                body=doc, 
                refresh=True
            )
            saved_ids.append(doc_id)
            print(f"ğŸ“¦ ì €ì¥ë¨: chunk {i} -> {doc_id}")
        except Exception as e:
            print(f"âŒ ì²­í¬ {i} ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    print(f"âœ… ì´ {len(saved_ids)}ê°œì˜ ì²­í¬ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return saved_ids

def search_chunks(
    client: OpenSearch,
    query: str,
    index_name: str = "document-chunks",
    size: int = 10
) -> List[Dict[str, Any]]:
    """
    OpenSearchì—ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        size: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
    """
    search_body = {
        "query": {
            "match": {
                "content": query
            }
        },
        "size": size,
        "_source": ["chunk_id", "content", "document_name", "timestamp", "metadata"]
    }
    
    try:
        response = client.search(index=index_name, body=search_body)
        hits = response['hits']['hits']
        
        results = []
        for hit in hits:
            result = {
                "id": hit["_id"],
                "score": hit["_score"],
                **hit["_source"]
            }
            results.append(result)
        
        return results
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

def vector_search_chunks(
    client: OpenSearch,
    query_vector: List[float],
    index_name: str = "document-chunks",
    size: int = 10,
    min_score: float = 0.7
) -> List[Dict[str, Any]]:
    """
    ë²¡í„° ìœ ì‚¬ë„ë¥¼ ì´ìš©í•´ OpenSearchì—ì„œ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        query_vector: ê²€ìƒ‰í•  ë²¡í„°
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        size: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        min_score: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜
        
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
    """
    search_body = {
        "query": {
            "knn": {
                "embedding": {
                    "vector": query_vector,
                    "k": size
                }
            }
        },
        "min_score": min_score,
        "size": size,
        "_source": ["chunk_id", "content", "document_name", "timestamp", "metadata"]
    }
    
    try:
        response = client.search(index=index_name, body=search_body)
        hits = response['hits']['hits']
        
        results = []
        for hit in hits:
            result = {
                "id": hit["_id"],
                "score": hit["_score"],
                **hit["_source"]
            }
            results.append(result)
        
        return results
    except Exception as e:
        print(f"âŒ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []

def hybrid_search_chunks(
    client: OpenSearch,
    query_text: str,
    query_vector: Optional[List[float]] = None,
    index_name: str = "document-chunks",
    size: int = 10,
    text_weight: float = 0.5,
    vector_weight: float = 0.5
) -> List[Dict[str, Any]]:
    """
    í…ìŠ¤íŠ¸ ê²€ìƒ‰ê³¼ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        client: OpenSearch í´ë¼ì´ì–¸íŠ¸
        query_text: ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        query_vector: ê²€ìƒ‰í•  ë²¡í„° (ì„ íƒì )
        index_name: ì¸ë±ìŠ¤ ì´ë¦„
        size: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        text_weight: í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        vector_weight: ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜
        
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡
    """
    if query_vector is None:
        # ë²¡í„°ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
        return search_chunks(client, query_text, index_name, size)
    
    search_body = {
        "query": {
            "bool": {
                "should": [
                    {
                        "match": {
                            "content": {
                                "query": query_text,
                                "boost": text_weight
                            }
                        }
                    },
                    {
                        "knn": {
                            "embedding": {
                                "vector": query_vector,
                                "k": size,
                                "boost": vector_weight
                            }
                        }
                    }
                ]
            }
        },
        "size": size,
        "_source": ["chunk_id", "content", "document_name", "timestamp", "metadata"]
    }
    
    try:
        response = client.search(index=index_name, body=search_body)
        hits = response['hits']['hits']
        
        results = []
        for hit in hits:
            result = {
                "id": hit["_id"],
                "score": hit["_score"],
                **hit["_source"]
            }
            results.append(result)
        
        return results
    except Exception as e:
        print(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        return []